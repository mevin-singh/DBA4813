{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# To ignore warnings in the notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = pd.read_csv('XWines_Full_100K_wines.csv')\n",
    "data = original[['WineName', 'Type', 'Grapes', 'Harmonize', 'ABV', 'Body', 'Acidity', 'Country', 'Vintages', 'Website']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to remove square brackets and quotation marks\n",
    "# to be used on Grapes, Harmonize and Vintages\n",
    "# inputs: data is the dataframe, column_names is the name of the column (string) or list\n",
    "def clean_column(data, column_names):\n",
    "    \n",
    "    for column_name in column_names:\n",
    "\n",
    "        if column_name in ['Grapes', 'Harmonize']:\n",
    "            # extracting all words inside \n",
    "            data[column_name] = data[column_name].apply(lambda x: re.findall(r\"'(.*?)'\", x))\n",
    "\n",
    "            # convert the list of words back to a string\n",
    "            data[column_name] = data[column_name].apply(lambda x: ', '.join(x))\n",
    "        \n",
    "        else: \n",
    "            # removing the square brackets\n",
    "            data[column_name] = data[column_name].apply(lambda x: str(x).strip('[]'))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = clean_column(original, ['Grapes', 'Harmonize', 'Vintages'])\n",
    "data = clean_column(data, ['Grapes', 'Harmonize', 'Vintages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to get the counts\n",
    "# inputs: data is the dataframe, columns_name are the list of columns to get the counts\n",
    "\n",
    "def get_counts(data, column_names):\n",
    "    for column_name in column_names:\n",
    "        data[column_name] = data[column_name].apply(lambda x: len(x.split(', ')))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_counts(data, ['Grapes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Poultry                58315\n",
       "Beef                   57774\n",
       "Lamb                   38725\n",
       "Game Meat              36436\n",
       "Pork                   25406\n",
       "                       ...  \n",
       "Spiced Fruit Cake          1\n",
       "Dried Fruits               1\n",
       "Curry Chicken              1\n",
       "Eggplant Parmigiana        1\n",
       "Paella                     1\n",
       "Name: count, Length: 66, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_foods = df['Harmonize'].str.split(', ', expand=True).stack().value_counts()\n",
    "\n",
    "unique_foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-classifying similar types of foods with the similar names into same categories\n",
    "red_meat = ['Beef', 'Pork', 'Lamb', 'Veal', 'Meat', 'Ham', 'Red Meat']\n",
    "white_meat = ['Chicken', 'Poultry', 'Duck', 'Cold Cuts']\n",
    "cheese = ['Mild Cheese', 'Medium-cured Cheese', 'Cheese', 'Soft Cheese', 'Maturated Cheese', 'Hard Cheese', 'Goat Cheese', 'Blue Cheese']\n",
    "seafood = ['Shellfish', 'Rich Fish', 'Lean Fish', 'Fish', 'Codfish', 'Seafood']\n",
    "italian = ['Pasta', 'Risotto', 'Tagliatelle', 'Lasagna', 'Eggplant Parmigiana', 'Pizza']\n",
    "dessert = ['Sweet Dessert', 'Fruit Dessert', 'Dessert', 'Citric Dessert', 'Cake', 'Souffl√©', 'Chocolate', 'Spiced Fruit Cake']\n",
    "vegetarian = ['Vegetarian', 'Mushrooms', 'Salad', 'Beans', 'Baked Potato', 'Chestnut']\n",
    "snacks = ['Snack', 'French Fries', 'Fruit', 'Cookies']\n",
    "others = ['Sushi', 'Sashimi', 'Yakissoba', 'Asian Food', 'Roast', 'Tomato Dishes', 'Cream', 'Curry Chicken', 'Barbeque', 'Light Stews', 'Paella', 'Grilled', 'Dried Fruits']\n",
    "appetizer = ['Appetizer', 'Aperitif']\n",
    "\n",
    "# checking if all other categories except Game Meat, Cured Meat and Spicy Food are classified\n",
    "# total 67 (64 + 3)\n",
    "# len(red_meat) + len(white_meat) + len(cheese) + len(seafood) + len(italian) + len(dessert) + len(vegetarian) + len(snacks) + len(others) + len(appetizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [red_meat, white_meat, cheese, seafood, italian, dessert, vegetarian, snacks, others, appetizer]\n",
    "names = ['Red Meat', 'White Meat', 'Cheese', 'Seafood', 'Italian', 'Dessert', 'Vegetarian', 'Snacks', 'Appetiser']\n",
    "\n",
    "# define a function to re-assign the categories for each row\n",
    "def reassign_categories(row):\n",
    "    # splitting the food in the string and making it a list\n",
    "    food_list = row.split(', ')\n",
    "\n",
    "    # iterate through the list and re-assign the categories\n",
    "    for i in range(len(food_list)):\n",
    "        for lst, name in zip(list_of_lists, names):\n",
    "            if food_list[i] in lst:\n",
    "                food_list[i] = name\n",
    "\n",
    "    # remove repeated food categories for each row\n",
    "    new_row = list(set(food_list))\n",
    "\n",
    "    # joining the list back into a string\n",
    "    new_row = ', '.join(new_row)\n",
    "\n",
    "    return new_row\n",
    "\n",
    "# apply the function to each row of the DataFrame\n",
    "df['Harmonize'] = df['Harmonize'].apply(reassign_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing '-bodied' from body column\n",
    "df['Body'] = df['Body'].str.replace('-bodied', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data\n",
    "df.to_csv('wines_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding the harmonise column\n",
    "# Step 1: Create a list of all unique food types\n",
    "food_types = df['Harmonize'].str.split(', ').explode().unique()\n",
    "food_types = ['Harmonize_' + food_type for food_type in food_types]\n",
    "\n",
    "# Step 2: Create a new DataFrame with a column for each unique food type\n",
    "dummies = df['Harmonize'].str.get_dummies(', ').reindex(columns=food_types, fill_value=0)\n",
    "\n",
    "# Step 3: Concatenate the original DataFrame with the new DataFrame\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "df = df.drop(columns=['Harmonize', 'Vintages', 'Website', 'WineName'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace dessert/port to just dessert wine\n",
    "df['Type'] = df['Type'].str.replace('Dessert/Port', 'Dessert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only countries that appear more than 700 times\n",
    "df = df[df['Country'].isin(['France', 'Italy', 'United States', 'Spain', 'Portugal', 'Germany', 'Australia', 'South Africa', 'Austria', 'Brazil', 'New Zealand', 'Canada', 'Switzerland'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test\n",
    "X = df.drop(columns = ['Type'])\n",
    "y = df['Type']\n",
    "\n",
    "# train_test_split on dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mevin/DBA4813/Source Code.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mevin/DBA4813/Source%20Code.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# checking if there is imbalanced data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mevin/DBA4813/Source%20Code.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y\u001b[39m.\u001b[39mvalue_counts(normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mevin/DBA4813/Source%20Code.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mevin/DBA4813/Source%20Code.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mThere is imbalanced data so we should use ensemble techniques \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mevin/DBA4813/Source%20Code.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "# checking if there is imbalanced data\n",
    "y.value_counts(normalize=True)\n",
    "\n",
    "'''\n",
    "There is imbalanced data so we should use ensemble techniques \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get all categorical variables\n",
    "\n",
    "def getCategorical(X_train, data):\n",
    "    categorical_variables = []\n",
    "    \n",
    "    for column in X_train.columns:\n",
    "        if data[column].dtype == \"object\":\n",
    "            categorical_variables.append(column)\n",
    "\n",
    "    return categorical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a transformer to encode categorical variables\n",
    "\n",
    "def transformer(categorical_variables):\n",
    "    # One-hot encoding\n",
    "    enc_rf = OneHotEncoder(sparse_output = False, handle_unknown = \"ignore\")\n",
    "\n",
    "    transformer_rf = ColumnTransformer([\n",
    "        (\"categorical\", enc_rf, categorical_variables)\n",
    "    ], remainder=\"passthrough\")\n",
    "\n",
    "    return transformer_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to transform data\n",
    "\n",
    "def transformData(X_train, X_test, transformer_rf):\n",
    "    # when making predictions, there is no X_train and X_test\n",
    "    # this condition is to handle that case\n",
    "    if X_train is X_test:\n",
    "        X_encoded = pd.DataFrame(transformer_rf.fit_transform(X_train), columns = transformer_rf.get_feature_names_out())\n",
    "        \n",
    "        return X_encoded\n",
    "\n",
    "    else:  \n",
    "        X_train_encoded_rf = pd.DataFrame(transformer_rf.fit_transform(X_train), columns = transformer_rf.get_feature_names_out())\n",
    "        X_test_encoded_rf = pd.DataFrame(transformer_rf.fit_transform(X_test), columns = transformer_rf.get_feature_names_out())\n",
    "        \n",
    "        return [X_train_encoded_rf, X_test_encoded_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to rename the column to increase readability\n",
    "\n",
    "def renameCol(categorical_variables, X_train_encoded_rf, X_test_encoded_rf):\n",
    "    \n",
    "    X_train_encoded_rf.columns = X_train_encoded_rf.columns.str.replace(re.compile(r'categorical__|remainder__'), '', regex = True)\n",
    "    X_test_encoded_rf.columns = X_test_encoded_rf.columns.str.replace(re.compile(r'categorical__|remainder__'), '', regex = True)\n",
    "\n",
    "    # used when making predictions\n",
    "    if X_train_encoded_rf is X_test_encoded_rf:\n",
    "        X_encoded = X_train_encoded_rf\n",
    "        \n",
    "        return X_encoded\n",
    "    \n",
    "    else:   \n",
    "            return [X_train_encoded_rf, X_test_encoded_rf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that combines all the above functions into a function called preprocess\n",
    "def preprocess(X_train, X_test, data):\n",
    "    \n",
    "    # use the getCategorical function to get categorical variables in the dataset\n",
    "    categorical_variables = getCategorical(X_train, data)\n",
    "    \n",
    "    # use tranformer function to create the transformer\n",
    "    transformer_rf = transformer(categorical_variables)\n",
    "    \n",
    "    # use transformData function\n",
    "    X_train_encoded_rf, X_test_encoded_rf = transformData(X_train, X_test, transformer_rf)\n",
    "\n",
    "    # renaming the columns for readability\n",
    "    X_train_encoded_rf, X_test_encoded_rf = renameCol(categorical_variables, X_train_encoded_rf, X_test_encoded_rf)\n",
    "\n",
    "    return [X_train_encoded_rf, X_test_encoded_rf, transformer_rf]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpacking values\n",
    "X_train_encoded_rf, X_test_encoded_rf, transformer_rf = preprocess(X_train, X_test, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = 'balanced' is used to give more weight to minority class\n",
    "# the classes will be weighted inversely proportional to how frequently they appear in the data\n",
    "\n",
    "rf = RandomForestClassifier(criterion = 'entropy', \n",
    "                            max_depth = 5, \n",
    "                            min_samples_leaf = 8, \n",
    "                            min_samples_split = 5, \n",
    "                            n_estimators = 100,\n",
    "                            class_weight = 'balanced', \n",
    "                            random_state = 100)\n",
    "\n",
    "rf.fit(X_train_encoded_rf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pipeline\n",
    "pipeline_rf = Pipeline([(\"transformer\", transformer_rf), (\"random_forest\", rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for cross validating\n",
    "def show_cv_results(pipeline):\n",
    "  scores = cross_validate(pipeline, X_train, y_train, cv = 10, return_train_score = True)\n",
    "  print(\"Mean test score:\", scores[\"test_score\"].mean())\n",
    "  display(pd.DataFrame(scores))\n",
    "\n",
    "show_cv_results(pipeline_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to calcualte AUC score for the model\n",
    "\n",
    "def get_AUC (model, X, y):\n",
    "    \n",
    "    ###########\n",
    "    # Calculate the AUC score.\n",
    "    # Input: reg_model is the classifier, X is the X_test, Y is Y_test\n",
    "    # Output: The AUC value.\n",
    "    ###########\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict_proba(X)\n",
    "\n",
    "    # Calculate the AUC score\n",
    "    auc_score = roc_auc_score(y, y_pred, multi_class='ovr')\n",
    "   \n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters tuning\n",
    "grid_rf = {\n",
    "    'random_forest__n_estimators': [80, 100, 200, 300],\n",
    "    'random_forest__max_depth': [5, 10, 15, 20],\n",
    "    'random_forest__min_samples_split': [3, 5, 8, 10],\n",
    "    'random_forest__min_samples_leaf': [2, 3, 5, 8]\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(estimator = pipeline_rf,\n",
    "                      param_grid = grid_rf,\n",
    "                      cv = 10,\n",
    "                      n_jobs = -1,\n",
    "                      return_train_score = True)\n",
    "\n",
    "rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to view grid search results\n",
    "\n",
    "def report_GridSearchCV_results(gs):\n",
    "    print(\"Best combination of hyperparams:\\n\", gs.best_params_, \"\\n\")\n",
    "    print(\"Best mean_test_score score:\\n\", gs.best_score_, \"\\n\")\n",
    "    \n",
    "    scores = []\n",
    "    for i in range(gs.n_splits_):\n",
    "        scores.append(gs.cv_results_['split{}_test_score'.format(i)][gs.best_index_])\n",
    "    print(\"Score by fold for best estimator:\\n\", scores, \"\\n\")\n",
    "    \n",
    "    # View top 5 hyperparams combinations by mean_test_score (mean on \"validation\" set)\n",
    "    print(\"Top 5 hyperparams combinations by mean_test_score:\")\n",
    "    display(pd.DataFrame(gs.cv_results_)[[\"rank_test_score\", \"mean_test_score\"] \n",
    "                                            + [\"param_\" + param for param in gs.param_grid]]\\\n",
    "              .sort_values(by = \"mean_test_score\", ascending = False)\\\n",
    "              .set_index(\"rank_test_score\").head(5))\n",
    "\n",
    "\n",
    "report_GridSearchCV_results(rf_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = rf_gs.best_params_\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = best_params['random_forest__n_estimators'],  \n",
    "                             max_depth = best_params['random_forest__max_depth'],\n",
    "                             min_samples_split = best_params['random_forest__min_samples_split'], \n",
    "                             min_samples_leaf = best_params['random_forest__min_samples_leaf'],\n",
    "                             class_weight='balanced',\n",
    "                             random_state = 100)\n",
    "\n",
    "clf.fit(X_train_encoded_rf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on the test set\n",
    "\n",
    "def score_model(model, x, y):\n",
    "    pred = model.predict(x)\n",
    "    print(classification_report(y, pred))\n",
    "\n",
    "    cm = confusion_matrix(y, pred)\n",
    "    columns = np.unique(y)\n",
    "    df_cm = pd.DataFrame(cm, index=columns, columns=columns)\n",
    "    ax = sns.heatmap(df_cm, cmap='Oranges', annot=True, fmt='g')\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "score_model(clf, X_test_encoded_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC scores\n",
    "base_model = round(get_AUC(rf, X_test_encoded_rf, y_test), 2)\n",
    "best_model = round(get_AUC(clf, X_test_encoded_rf, y_test), 2)\n",
    "\n",
    "# increase in peformance\n",
    "improvement = round((best_model - base_model)/base_model * 100, 2)\n",
    "\n",
    "print(f'The AUC of the base model is: {base_model}')\n",
    "print(f'The AUC of the best model is: {best_model}')\n",
    "print(f'The improvement in performance is: {improvement}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get feature importance    \n",
    "def plot_importance(model, X):\n",
    "\n",
    "    importances = pd.Series(data=model.feature_importances_,\n",
    "                            index= list(X.columns))\n",
    "    \n",
    "    importances_sorted = importances.sort_values()\n",
    "    \n",
    "    importances_sorted = importances_sorted[-10:]\n",
    "\n",
    "    plt.figure(figsize = (12, 5))\n",
    "    importances_sorted.plot(kind='barh', color='blue')\n",
    "    plt.title('Top 10 Feature Importance')\n",
    "    plt.xlabel(\"Importance\", fontweight = 'bold')\n",
    "    plt.ylabel(\"Features\", fontweight = 'bold')\n",
    "    plt.show()\n",
    "\n",
    "plot_importance(rf_gs.best_estimator_.named_steps[\"random_forest\"], X_train_encoded_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
